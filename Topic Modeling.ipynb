{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from gensim import matutils, models\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "This is perhaps the most analysis from all notebooks - but also one of the more difficult to achieve some nice result. Let's try it!\n",
    "\n",
    "We start by loading our Document Term Matrix and cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2Pac</th>\n",
       "      <th>Cardi B</th>\n",
       "      <th>Eminem</th>\n",
       "      <th>J. Cole</th>\n",
       "      <th>Joyner Lucas</th>\n",
       "      <th>Juice WRLD</th>\n",
       "      <th>Kanye West</th>\n",
       "      <th>Lil Pump</th>\n",
       "      <th>Logic</th>\n",
       "      <th>Mac Miller</th>\n",
       "      <th>Nas</th>\n",
       "      <th>Nicki Minaj</th>\n",
       "      <th>Notorious B.I.G.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaack</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            2Pac  Cardi B  Eminem  J. Cole  Joyner Lucas  Juice WRLD  \\\n",
       "aa             0        0       1        0             0           0   \n",
       "aaaaaaaaaa     0        0       0        0             0           0   \n",
       "aaaaaaack      0        0       1        0             0           0   \n",
       "aaaaah         0        0       0        0             0           0   \n",
       "aaaaahhh       0        0       0        0             0           0   \n",
       "\n",
       "            Kanye West  Lil Pump  Logic  Mac Miller  Nas  Nicki Minaj  \\\n",
       "aa                   1         0      1           0    0            0   \n",
       "aaaaaaaaaa           0         0      0           0    0            1   \n",
       "aaaaaaack            0         0      0           0    0            0   \n",
       "aaaaah               0         0      0           0    0            1   \n",
       "aaaaahhh             1         0      0           0    0            0   \n",
       "\n",
       "            Notorious B.I.G.  \n",
       "aa                         0  \n",
       "aaaaaaaaaa                 0  \n",
       "aaaaaaack                  0  \n",
       "aaaaah                     0  \n",
       "aaaaahhh                   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data_cleaned = pd.read_pickle('data_clean.pkl')\n",
    "term_doc_matrix = data.transpose()\n",
    "term_doc_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some mino preprocessing again. We will remove the stop words and only take nouns, adjectives and verbs into account. If you want to do your topic modeling, you can always play around with your own choice. Maybe only nouns and adjectives achieve a better result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj_verbs(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ' or pos[:2] == 'VV'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "add_stop_words = ['im', 'got', 'like',\n",
    "                 'dont', 'know', 'just',\n",
    "                 'fuck', 'shit', 'yeah',\n",
    "                 'aint', 'thats', 'make',\n",
    "                 'bitch', 'love', 'wanna', \n",
    "                 'cause', 'n*ggas', 'n*gga', \n",
    "                 'time', 'em', 'man', \n",
    "                  'want', 'let', 'come']\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "cv = CountVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2Pac</th>\n",
       "      <td>aint nothin gangsta party eh light ahh nothin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardi B</th>\n",
       "      <td>whores house whores house whores house whores ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>yeah i guess huh obvious eye eye funny much i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J. Cole</th>\n",
       "      <td>work growth famous important anything anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joyner Lucas</th>\n",
       "      <td>fall fall i more i i werent cant picture someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Juice WRLD</th>\n",
       "      <td>nahnahnahnahnahnah smoke cigarettes cancer che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kanye West</th>\n",
       "      <td>hour hour power minute minute lord second seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lil Pump</th>\n",
       "      <td>lyrics first snippet elliot dinner brr man ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logic</th>\n",
       "      <td>lyrics song please song welcome pressure progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mac Miller</th>\n",
       "      <td>youre young much matters something night dream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>yeah hello ladies gentlemen i fade famous chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicki Minaj</th>\n",
       "      <td>marxist ways only phase money money money worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notorious B.I.G.</th>\n",
       "      <td>grip motherfucker yeah album teachers amount p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             lyrics\n",
       "2Pac              aint nothin gangsta party eh light ahh nothin ...\n",
       "Cardi B           whores house whores house whores house whores ...\n",
       "Eminem            yeah i guess huh obvious eye eye funny much i ...\n",
       "J. Cole           work growth famous important anything anything...\n",
       "Joyner Lucas      fall fall i more i i werent cant picture someo...\n",
       "Juice WRLD        nahnahnahnahnahnah smoke cigarettes cancer che...\n",
       "Kanye West        hour hour power minute minute lord second seco...\n",
       "Lil Pump          lyrics first snippet elliot dinner brr man ben...\n",
       "Logic             lyrics song please song welcome pressure progr...\n",
       "Mac Miller        youre young much matters something night dream...\n",
       "Nas               yeah hello ladies gentlemen i fade famous chai...\n",
       "Nicki Minaj       marxist ways only phase money money money worl...\n",
       "Notorious B.I.G.  grip motherfucker yeah album teachers amount p..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj_verbs = pd.DataFrame(data_cleaned.lyrics.apply(nouns_adj_verbs))\n",
    "data_nouns_adj_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with only these three kinds of word and without stopwords the text still does make some sense to us humans. Hopefully the same goes for the machine! But let's create a DTM again of our intermediate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaack</th>\n",
       "      <th>aaaaahhh</th>\n",
       "      <th>aaaaayyyyooooo</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahh</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaahhh</th>\n",
       "      <th>aaand</th>\n",
       "      <th>aaass</th>\n",
       "      <th>...</th>\n",
       "      <th>世界中で聴いてる</th>\n",
       "      <th>帰っていただいて結構</th>\n",
       "      <th>彼の行動が気になって仕方ないはず</th>\n",
       "      <th>感謝しています</th>\n",
       "      <th>最高だったでしょう</th>\n",
       "      <th>本当はロジックを愛してやまないんでしょう</th>\n",
       "      <th>楽しんでいただけたことを願っています</th>\n",
       "      <th>毎日</th>\n",
       "      <th>私たちは共に歴史を刻んできた</th>\n",
       "      <th>耳を塞ぐか</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2Pac</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardi B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J. Cole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joyner Lucas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Juice WRLD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kanye West</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lil Pump</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logic</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mac Miller</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicki Minaj</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notorious B.I.G.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 28668 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aa  aaaaaaack  aaaaahhh  aaaaayyyyooooo  aaaah  aaaahh  \\\n",
       "2Pac               0          0         0               0      0       0   \n",
       "Cardi B            0          0         0               0      0       0   \n",
       "Eminem             1          1         0               0      0       0   \n",
       "J. Cole            0          0         0               0      0       0   \n",
       "Joyner Lucas       0          0         0               0      0       0   \n",
       "Juice WRLD         0          0         0               0      0       0   \n",
       "Kanye West         0          0         1               0      3       1   \n",
       "Lil Pump           0          0         0               0      0       0   \n",
       "Logic              1          0         0               0      0       0   \n",
       "Mac Miller         0          0         0               0      0       0   \n",
       "Nas                0          0         0               0      0       0   \n",
       "Nicki Minaj        0          0         0               1      0       0   \n",
       "Notorious B.I.G.   0          0         0               0      0       0   \n",
       "\n",
       "                  aaaand  aaahhh  aaand  aaass  ...  世界中で聴いてる  帰っていただいて結構  \\\n",
       "2Pac                   0       0      0      0  ...         0           0   \n",
       "Cardi B                0       0      0      0  ...         0           0   \n",
       "Eminem                 0       1      0      0  ...         0           0   \n",
       "J. Cole                0       0      0      0  ...         0           0   \n",
       "Joyner Lucas           0       0      0      0  ...         0           0   \n",
       "Juice WRLD             0       0      0      0  ...         0           0   \n",
       "Kanye West             0       0      0      0  ...         0           0   \n",
       "Lil Pump               0       0      0      0  ...         0           0   \n",
       "Logic                  0       0      0      0  ...         1           1   \n",
       "Mac Miller             1       0      0      0  ...         0           0   \n",
       "Nas                    0       0      0      0  ...         0           0   \n",
       "Nicki Minaj            0       0      1      1  ...         0           0   \n",
       "Notorious B.I.G.       0       1      0      0  ...         0           0   \n",
       "\n",
       "                  彼の行動が気になって仕方ないはず  感謝しています  最高だったでしょう  本当はロジックを愛してやまないんでしょう  \\\n",
       "2Pac                             0        0          0                     0   \n",
       "Cardi B                          0        0          0                     0   \n",
       "Eminem                           0        0          0                     0   \n",
       "J. Cole                          0        0          0                     0   \n",
       "Joyner Lucas                     0        0          0                     0   \n",
       "Juice WRLD                       0        0          0                     0   \n",
       "Kanye West                       0        0          0                     0   \n",
       "Lil Pump                         0        0          0                     0   \n",
       "Logic                            1        1          1                     1   \n",
       "Mac Miller                       0        0          0                     0   \n",
       "Nas                              0        0          0                     0   \n",
       "Nicki Minaj                      0        0          0                     0   \n",
       "Notorious B.I.G.                 0        0          0                     0   \n",
       "\n",
       "                  楽しんでいただけたことを願っています  毎日  私たちは共に歴史を刻んできた  耳を塞ぐか  \n",
       "2Pac                               0   0               0      0  \n",
       "Cardi B                            0   0               0      0  \n",
       "Eminem                             0   0               0      0  \n",
       "J. Cole                            0   0               0      0  \n",
       "Joyner Lucas                       0   0               0      0  \n",
       "Juice WRLD                         0   0               0      0  \n",
       "Kanye West                         0   0               0      0  \n",
       "Lil Pump                           0   0               0      0  \n",
       "Logic                              1   1               1      1  \n",
       "Mac Miller                         0   0               0      0  \n",
       "Nas                                0   0               0      0  \n",
       "Nicki Minaj                        0   0               0      0  \n",
       "Notorious B.I.G.                   0   0               0      0  \n",
       "\n",
       "[13 rows x 28668 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cv = cv.fit_transform(data_nouns_adj_verbs.lyrics)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_nouns_adj_verbs.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the topic modeling algorithm. We will use [Laten Dirichlect Allocation](https://de.wikipedia.org/wiki/Latent_Dirichlet_Allocation) (LDA). I recommend you to read [this excellent article](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/) on how LDA works.\n",
    "\n",
    "We will give an overview for each rapper, which of the words have the highest probability (eahc word individually in a topic) to appear together with other words. We set the boundary for number of topics to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2e637d77faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparse2Corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matutils' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtm.transpose()))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"brr\" + 0.010*\"chyeah\" + 0.010*\"racks\" + 0.009*\"yuh\" + 0.008*\"vroom\" + 0.007*\"slatt\" + 0.006*\"goyard\" + 0.005*\"esskeetit\" + 0.005*\"pinky\" + 0.005*\"fasho\"'),\n",
       " (1,\n",
       "  '0.009*\"biggie\" + 0.007*\"je\" + 0.006*\"nicki\" + 0.006*\"funk\" + 0.004*\"cole\" + 0.004*\"cardi\" + 0.004*\"que\" + 0.004*\"dem\" + 0.003*\"combs\" + 0.003*\"buck\"'),\n",
       " (2,\n",
       "  '0.011*\"buck\" + 0.008*\"joyner\" + 0.005*\"yayo\" + 0.004*\"wha\" + 0.003*\"jurisdiction\" + 0.003*\"yup\" + 0.003*\"cha\" + 0.002*\"bah\" + 0.002*\"blat\" + 0.002*\"isis\"'),\n",
       " (3,\n",
       "  '0.004*\"nas\" + 0.004*\"woah\" + 0.003*\"shady\" + 0.002*\"cmon\" + 0.002*\"demons\" + 0.002*\"outlaw\" + 0.002*\"pac\" + 0.002*\"codeine\" + 0.001*\"dre\" + 0.001*\"dig\"'),\n",
       " (4,\n",
       "  '0.004*\"logic\" + 0.002*\"bam\" + 0.002*\"kanye\" + 0.002*\"monster\" + 0.002*\"miller\" + 0.002*\"sinatra\" + 0.002*\"yeezy\" + 0.001*\"cuz\" + 0.001*\"rhymes\" + 0.001*\"roc\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=5, id2word=id2word, passes=80)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, '2Pac'),\n",
       " (1, 'Cardi B'),\n",
       " (3, 'Eminem'),\n",
       " (1, 'J. Cole'),\n",
       " (2, 'Joyner Lucas'),\n",
       " (3, 'Juice WRLD'),\n",
       " (4, 'Kanye West'),\n",
       " (0, 'Lil Pump'),\n",
       " (4, 'Logic'),\n",
       " (4, 'Mac Miller'),\n",
       " (3, 'Nas'),\n",
       " (1, 'Nicki Minaj'),\n",
       " (1, 'Notorious B.I.G.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_transformed = lda[corpus]\n",
    "list(zip([a[0][0] for a in corpus_transformed], data_dtm.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "lda_sk = LDA(n_components=5, n_jobs=-1)\n",
    "lda_sk.fit(data_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this again but with another Library called [pyLDAvis](https://github.com/bmabey/pyLDAvis). The nice thing about this LDA lib is that it already creates an interactive visualization of the results and saves it in an html file. Data Science wouldn't be complete without any visualizations after all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import os\n",
    "import pyLDAvis\n",
    "\n",
    "LDAvis_data_filepath = os.path.join('./ldavis')\n",
    "\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda_sk, data_cv, cv)\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "    \n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results might be a bit difficult. In general rappers tend to talk about themselves, which is why we often see their name in the result.\n",
    "\n",
    "However topic 3 has words like 'codeine' and 'demons' which might be referred to lyrics about mental state and depression - probably Juice WRLD?\n",
    "\n",
    "But overall this section certainly needs some tweaking, the topics are quite difficult to interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "shady cole buck dre miller thoughts superman duh rhyme joyner\n",
      "\n",
      "Topic #1:\n",
      "cardi bam kanye monster yeezy roc hoo hype cmon chi\n",
      "\n",
      "Topic #2:\n",
      "nas cmon outlaw pac row heaven dogg soldier queensbridge mob\n",
      "\n",
      "Topic #3:\n",
      "woah racks codeine demons brr yuh dig percs choppa skrrt\n",
      "\n",
      "Topic #4:\n",
      "biggie je nicki funk logic dem buck combs que cmon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/.local/share/virtualenvs/Rap-lyrics-visualizations-h4OBEXz0/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1080\"\n",
       "            height=\"720\"\n",
       "            src=\"./ldavis.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f40ad14f510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda_sk.components_):\n",
    "    print(\"\\nTopic #%d:\" % topic_idx)\n",
    "    print(\" \".join([words[i] for i in topic.argsort()[:-11:-1]]))\n",
    "\n",
    "IFrame(src='./ldavis.html', width=1080, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's have a look on the distance between the topic. Note that the numbers i of one bubble in this visualization represents the topic n-1 from previous cell.\n",
    "\n",
    "As mentioned earlier, rappers tend to talk about themselves - Topic 1, 2 and 5 (0, 1 and 4 in previous cell) most often contain the name of these artists. And in the visualization these bubbles are very close. So my assumption might be true (at least partially)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
